{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eeb0d79-0234-4868-9e03-76d4bfda6fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 33\n",
      "Training samples: 22545, Validation samples: 5637\n",
      "Using device: cpu\n",
      "\n",
      "LeNet-5 Architecture:\n",
      "LeNet5Tifinagh(\n",
      "  (conv_layers): Sequential(\n",
      "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): Tanh()\n",
      "    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (4): Tanh()\n",
      "    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    (6): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (7): Tanh()\n",
      "  )\n",
      "  (fc_layers): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=9720, out_features=84, bias=True)\n",
      "    (2): Tanh()\n",
      "    (3): Linear(in_features=84, out_features=33, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Total parameters: 870,061\n",
      "Trainable parameters: 870,061\n",
      "\n",
      "Starting LeNet-5 Training...\n",
      "============================================================\n",
      "\n",
      "Epoch [1/10]\n",
      "  Batch [0/705], Loss: 3.4762\n",
      "  Batch [50/705], Loss: 2.6460\n",
      "  Batch [100/705], Loss: 2.3204\n",
      "  Batch [150/705], Loss: 1.4223\n",
      "  Batch [200/705], Loss: 1.4796\n",
      "  Batch [250/705], Loss: 1.2987\n",
      "  Batch [300/705], Loss: 0.9864\n",
      "  Batch [350/705], Loss: 1.1225\n",
      "  Batch [400/705], Loss: 1.0891\n",
      "  Batch [450/705], Loss: 0.8537\n",
      "  Batch [500/705], Loss: 0.7624\n",
      "  Batch [550/705], Loss: 0.6179\n",
      "  Batch [600/705], Loss: 0.7859\n",
      "  Batch [650/705], Loss: 0.8748\n",
      "  Batch [700/705], Loss: 0.4525\n",
      "Train Loss: 1.2850, Train Acc: 65.70%\n",
      "Val Loss: 0.6239, Val Acc: 83.41%\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch [2/10]\n",
      "  Batch [0/705], Loss: 0.5595\n",
      "  Batch [50/705], Loss: 0.5180\n",
      "  Batch [100/705], Loss: 0.4274\n",
      "  Batch [150/705], Loss: 0.2716\n",
      "  Batch [200/705], Loss: 0.3753\n",
      "  Batch [250/705], Loss: 0.4683\n",
      "  Batch [300/705], Loss: 0.3535\n",
      "  Batch [350/705], Loss: 0.2009\n",
      "  Batch [400/705], Loss: 0.4953\n",
      "  Batch [450/705], Loss: 0.2202\n",
      "  Batch [500/705], Loss: 0.4890\n",
      "  Batch [550/705], Loss: 0.2198\n",
      "  Batch [600/705], Loss: 0.4304\n",
      "  Batch [650/705], Loss: 0.2050\n",
      "  Batch [700/705], Loss: 0.4474\n",
      "Train Loss: 0.4163, Train Acc: 89.12%\n",
      "Val Loss: 0.2779, Val Acc: 93.22%\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch [3/10]\n",
      "  Batch [0/705], Loss: 0.1800\n",
      "  Batch [50/705], Loss: 0.1387\n",
      "  Batch [100/705], Loss: 0.1456\n",
      "  Batch [150/705], Loss: 0.4161\n",
      "  Batch [200/705], Loss: 0.1092\n",
      "  Batch [250/705], Loss: 0.2851\n",
      "  Batch [300/705], Loss: 0.2156\n",
      "  Batch [350/705], Loss: 0.1240\n",
      "  Batch [400/705], Loss: 0.1633\n",
      "  Batch [450/705], Loss: 0.1169\n",
      "  Batch [500/705], Loss: 0.1429\n",
      "  Batch [550/705], Loss: 0.0771\n",
      "  Batch [600/705], Loss: 0.2686\n",
      "  Batch [650/705], Loss: 0.2204\n",
      "  Batch [700/705], Loss: 0.1445\n",
      "Train Loss: 0.2016, Train Acc: 94.92%\n",
      "Val Loss: 0.1639, Val Acc: 96.15%\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch [4/10]\n",
      "  Batch [0/705], Loss: 0.0928\n",
      "  Batch [50/705], Loss: 0.1149\n",
      "  Batch [100/705], Loss: 0.0759\n",
      "  Batch [150/705], Loss: 0.1138\n",
      "  Batch [200/705], Loss: 0.1160\n",
      "  Batch [250/705], Loss: 0.2158\n",
      "  Batch [300/705], Loss: 0.1762\n",
      "  Batch [350/705], Loss: 0.1667\n",
      "  Batch [400/705], Loss: 0.1711\n",
      "  Batch [450/705], Loss: 0.0757\n",
      "  Batch [500/705], Loss: 0.0534\n",
      "  Batch [550/705], Loss: 0.1068\n",
      "  Batch [600/705], Loss: 0.1587\n",
      "  Batch [650/705], Loss: 0.1346\n",
      "  Batch [700/705], Loss: 0.1648\n",
      "Train Loss: 0.1281, Train Acc: 96.80%\n",
      "Val Loss: 0.1349, Val Acc: 96.29%\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch [5/10]\n",
      "  Batch [0/705], Loss: 0.1572\n",
      "  Batch [50/705], Loss: 0.0619\n",
      "  Batch [100/705], Loss: 0.0742\n",
      "  Batch [150/705], Loss: 0.0576\n",
      "  Batch [200/705], Loss: 0.0959\n",
      "  Batch [250/705], Loss: 0.1410\n",
      "  Batch [300/705], Loss: 0.0789\n",
      "  Batch [350/705], Loss: 0.1320\n",
      "  Batch [400/705], Loss: 0.0673\n",
      "  Batch [450/705], Loss: 0.0283\n",
      "  Batch [500/705], Loss: 0.0479\n",
      "  Batch [550/705], Loss: 0.0964\n",
      "  Batch [600/705], Loss: 0.0375\n",
      "  Batch [650/705], Loss: 0.0404\n",
      "  Batch [700/705], Loss: 0.1148\n",
      "Train Loss: 0.0872, Train Acc: 97.89%\n",
      "Val Loss: 0.1154, Val Acc: 96.54%\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch [6/10]\n",
      "  Batch [0/705], Loss: 0.0311\n",
      "  Batch [50/705], Loss: 0.0422\n",
      "  Batch [100/705], Loss: 0.0630\n",
      "  Batch [150/705], Loss: 0.0679\n",
      "  Batch [200/705], Loss: 0.0258\n",
      "  Batch [250/705], Loss: 0.0306\n",
      "  Batch [300/705], Loss: 0.0569\n",
      "  Batch [350/705], Loss: 0.0286\n",
      "  Batch [400/705], Loss: 0.0218\n",
      "  Batch [450/705], Loss: 0.0275\n",
      "  Batch [500/705], Loss: 0.0263\n",
      "  Batch [550/705], Loss: 0.0519\n",
      "  Batch [600/705], Loss: 0.0167\n",
      "  Batch [650/705], Loss: 0.1013\n",
      "  Batch [700/705], Loss: 0.0943\n",
      "Train Loss: 0.0571, Train Acc: 98.89%\n",
      "Val Loss: 0.0770, Val Acc: 97.71%\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch [7/10]\n",
      "  Batch [0/705], Loss: 0.0307\n",
      "  Batch [50/705], Loss: 0.0829\n",
      "  Batch [100/705], Loss: 0.0481\n",
      "  Batch [150/705], Loss: 0.0307\n",
      "  Batch [200/705], Loss: 0.0495\n",
      "  Batch [250/705], Loss: 0.0455\n",
      "  Batch [300/705], Loss: 0.0262\n",
      "  Batch [350/705], Loss: 0.0120\n",
      "  Batch [400/705], Loss: 0.0163\n",
      "  Batch [450/705], Loss: 0.0336\n",
      "  Batch [500/705], Loss: 0.0679\n",
      "  Batch [550/705], Loss: 0.0741\n",
      "  Batch [600/705], Loss: 0.0237\n",
      "  Batch [650/705], Loss: 0.0419\n",
      "  Batch [700/705], Loss: 0.0396\n",
      "Train Loss: 0.0378, Train Acc: 99.36%\n",
      "Val Loss: 0.0639, Val Acc: 98.35%\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch [8/10]\n",
      "  Batch [0/705], Loss: 0.0473\n",
      "  Batch [50/705], Loss: 0.0679\n",
      "  Batch [100/705], Loss: 0.0189\n",
      "  Batch [150/705], Loss: 0.0288\n",
      "  Batch [200/705], Loss: 0.0363\n",
      "  Batch [250/705], Loss: 0.0084\n",
      "  Batch [300/705], Loss: 0.0094\n",
      "  Batch [350/705], Loss: 0.0109\n",
      "  Batch [400/705], Loss: 0.0142\n",
      "  Batch [450/705], Loss: 0.0130\n",
      "  Batch [500/705], Loss: 0.0391\n",
      "  Batch [550/705], Loss: 0.0290\n",
      "  Batch [600/705], Loss: 0.0401\n",
      "  Batch [650/705], Loss: 0.0755\n",
      "  Batch [700/705], Loss: 0.0307\n",
      "Train Loss: 0.0273, Train Acc: 99.54%\n",
      "Val Loss: 0.0498, Val Acc: 98.67%\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch [9/10]\n",
      "  Batch [0/705], Loss: 0.0255\n",
      "  Batch [50/705], Loss: 0.0301\n",
      "  Batch [100/705], Loss: 0.0217\n",
      "  Batch [150/705], Loss: 0.0134\n",
      "  Batch [200/705], Loss: 0.0084\n",
      "  Batch [250/705], Loss: 0.0096\n",
      "  Batch [300/705], Loss: 0.0106\n",
      "  Batch [350/705], Loss: 0.0078\n",
      "  Batch [400/705], Loss: 0.0111\n",
      "  Batch [450/705], Loss: 0.0163\n",
      "  Batch [500/705], Loss: 0.0267\n",
      "  Batch [550/705], Loss: 0.0252\n",
      "  Batch [600/705], Loss: 0.0244\n",
      "  Batch [650/705], Loss: 0.0266\n",
      "  Batch [700/705], Loss: 0.0277\n",
      "Train Loss: 0.0205, Train Acc: 99.64%\n",
      "Val Loss: 0.0498, Val Acc: 98.76%\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch [10/10]\n",
      "  Batch [0/705], Loss: 0.0179\n",
      "  Batch [50/705], Loss: 0.0225\n",
      "  Batch [100/705], Loss: 0.0081\n",
      "  Batch [150/705], Loss: 0.0101\n",
      "  Batch [200/705], Loss: 0.0049\n",
      "  Batch [250/705], Loss: 0.0096\n",
      "  Batch [300/705], Loss: 0.0391\n",
      "  Batch [350/705], Loss: 0.0097\n",
      "  Batch [400/705], Loss: 0.0221\n",
      "  Batch [450/705], Loss: 0.0106\n",
      "  Batch [500/705], Loss: 0.0126\n",
      "  Batch [550/705], Loss: 0.0109\n",
      "  Batch [600/705], Loss: 0.0150\n",
      "  Batch [650/705], Loss: 0.0084\n",
      "  Batch [700/705], Loss: 0.0044\n",
      "Train Loss: 0.0169, Train Acc: 99.71%\n",
      "Val Loss: 0.0470, Val Acc: 98.63%\n",
      "--------------------------------------------------\n",
      "\n",
      "================================================================================\n",
      "FINAL EVALUATION - LENET-5 ON TIFINAGH CHARACTERS\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "\n",
    "class AMHCDDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.labels_df = pd.read_csv(csv_file, header=None, names=['image_path', 'label'])\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        # Map unique labels to indices\n",
    "        self.label_map = {label: idx for idx, label in enumerate(sorted(self.labels_df['label'].unique()))}\n",
    "        self.idx_to_label = {idx: label for label, idx in self.label_map.items()}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels_df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.root_dir, self.labels_df.iloc[idx]['image_path'])\n",
    "        image = Image.open(img_path).convert('L')  # Grayscale\n",
    "        label = self.labels_df.iloc[idx]['label']\n",
    "        label_idx = self.label_map[label]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label_idx\n",
    "\n",
    "class LeNet5Tifinagh(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(LeNet5Tifinagh, self).__init__()\n",
    "        \n",
    "        # Convolutional layers (feature extraction)\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            # C1: First convolutional layer\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=0),\n",
    "            nn.Tanh(),  # Original LeNet-5 uses Tanh\n",
    "            \n",
    "            # S2: First subsampling layer (average pooling)\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            # C3: Second convolutional layer\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0),\n",
    "            nn.Tanh(),\n",
    "            \n",
    "            # S4: Second subsampling layer\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            # C5: Third convolutional layer (acts like fully connected)\n",
    "            nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5, stride=1, padding=0),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        # Calculate the flattened size after conv layers\n",
    "        # For 64x64 input: 64->60->30->26->13->9 (with kernel=5, no padding)\n",
    "        # For 32x32 input: 32->28->14->10->5->1\n",
    "        # We need to adapt for 64x64 input\n",
    "        self.conv_output_size = self._get_conv_output_size()\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            # F6: First fully connected layer\n",
    "            nn.Linear(self.conv_output_size, 84),\n",
    "            nn.Tanh(),\n",
    "            \n",
    "            # Output layer\n",
    "            nn.Linear(84, num_classes)\n",
    "        )\n",
    "    \n",
    "    def _get_conv_output_size(self):\n",
    "        # Create a dummy input to calculate the output size\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.zeros(1, 1, 64, 64)  # Batch size 1, 1 channel, 64x64\n",
    "            dummy_output = self.conv_layers(dummy_input)\n",
    "            return dummy_output.numel()  # Total number of elements\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "\n",
    "# Define transforms - resize to work better with LeNet-5 style\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),  # Keep 64x64 but ensure consistent size\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalize to [-1, 1]\n",
    "])\n",
    "\n",
    "# Create dataset\n",
    "dataset = AMHCDDataset(\n",
    "    csv_file='amhcd-data-64/labels-map.csv',\n",
    "    root_dir='amhcd-data-64',\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# Split dataset\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "\n",
    "# Number of classes\n",
    "num_classes = len(dataset.label_map)\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(f\"Training samples: {train_size}, Validation samples: {val_size}\")\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize LeNet-5 model\n",
    "model = LeNet5Tifinagh(num_classes=num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "# Print model architecture\n",
    "print(\"\\nLeNet-5 Architecture:\")\n",
    "print(model)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "\n",
    "# Loss and optimizer (using SGD as in original LeNet-5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)  # SGD with momentum\n",
    "\n",
    "# Training function\n",
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_idx, (images, labels) in enumerate(dataloader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        if batch_idx % 50 == 0:\n",
    "            print(f'  Batch [{batch_idx}/{len(dataloader)}], Loss: {loss.item():.4f}')\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_acc = 100 * correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "# Validation function\n",
    "def validate_epoch(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_acc = 100 * correct / total\n",
    "    return epoch_loss, epoch_acc, all_predictions, all_labels\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10  # Slightly more epochs for LeNet-5\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "print(\"\\nStarting LeNet-5 Training...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'\\nEpoch [{epoch+1}/{num_epochs}]')\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_acc, val_predictions, val_labels = validate_epoch(model, val_loader, criterion, device)\n",
    "    \n",
    "    # Store metrics\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "    \n",
    "    print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
    "    print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
    "    print('-' * 50)\n",
    "\n",
    "# Plot training curves\n",
    "def plot_training_curves(train_losses, val_losses, train_accuracies, val_accuracies):\n",
    "    plt.style.use('seaborn-v0_8')\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Loss curve\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "    ax1.plot(epochs, train_losses, 'b-', label='Training Loss', linewidth=2, marker='o')\n",
    "    ax1.plot(epochs, val_losses, 'r-', label='Validation Loss', linewidth=2, marker='s')\n",
    "    ax1.set_title('LeNet-5 Training and Validation Loss', fontsize=14, fontweight='bold')\n",
    "    ax1.set_xlabel('Epoch', fontsize=12)\n",
    "    ax1.set_ylabel('Loss', fontsize=12)\n",
    "    ax1.legend(fontsize=11)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.set_xlim(1, len(train_losses))\n",
    "    \n",
    "    # Accuracy curve\n",
    "    ax2.plot(epochs, train_accuracies, 'b-', label='Training Accuracy', linewidth=2, marker='o')\n",
    "    ax2.plot(epochs, val_accuracies, 'r-', label='Validation Accuracy', linewidth=2, marker='s')\n",
    "    ax2.set_title('LeNet-5 Training and Validation Accuracy', fontsize=14, fontweight='bold')\n",
    "    ax2.set_xlabel('Epoch', fontsize=12)\n",
    "    ax2.set_ylabel('Accuracy (%)', fontsize=12)\n",
    "    ax2.legend(fontsize=11)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.set_xlim(1, len(train_accuracies))\n",
    "    ax2.set_ylim(0, 100)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot confusion matrix\n",
    "def plot_confusion_matrix(y_true, y_pred, class_names):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    plt.figure(figsize=(14, 12))\n",
    "    \n",
    "    # Calculate percentages for better readability\n",
    "    cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "    \n",
    "    # Create annotations that show both count and percentage\n",
    "    annotations = np.empty_like(cm).astype(str)\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            annotations[i, j] = f'{cm[i, j]}\\n({cm_percent[i, j]:.1f}%)'\n",
    "    \n",
    "    sns.heatmap(cm, annot=annotations, fmt='', cmap='Blues', \n",
    "                xticklabels=class_names, yticklabels=class_names,\n",
    "                cbar_kws={'label': 'Number of Samples'})\n",
    "    \n",
    "    plt.title('LeNet-5 Confusion Matrix\\n(Count and Percentage)', fontsize=16, fontweight='bold', pad=20)\n",
    "    plt.xlabel('Predicted Label', fontsize=12)\n",
    "    plt.ylabel('True Label', fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return cm\n",
    "\n",
    "# Generate detailed evaluation report\n",
    "def generate_evaluation_report(y_true, y_pred, class_names):\n",
    "    report = classification_report(y_true, y_pred, target_names=class_names, output_dict=True)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"LENET-5 TIFINAGH CHARACTER RECOGNITION - EVALUATION REPORT\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    print(\"\\nDETAILED CLASSIFICATION REPORT:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "    \n",
    "    # Overall metrics\n",
    "    accuracy = report['accuracy']\n",
    "    macro_avg = report['macro avg']\n",
    "    weighted_avg = report['weighted avg']\n",
    "    \n",
    "    print(\"SUMMARY METRICS:\")\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Overall Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    print(f\"Macro Average Precision: {macro_avg['precision']:.4f}\")\n",
    "    print(f\"Macro Average Recall: {macro_avg['recall']:.4f}\")\n",
    "    print(f\"Macro Average F1-Score: {macro_avg['f1-score']:.4f}\")\n",
    "    print(f\"Weighted Average Precision: {weighted_avg['precision']:.4f}\")\n",
    "    print(f\"Weighted Average Recall: {weighted_avg['recall']:.4f}\")\n",
    "    print(f\"Weighted Average F1-Score: {weighted_avg['f1-score']:.4f}\")\n",
    "    \n",
    "    # Per-class analysis\n",
    "    print(\"\\nPER-CLASS PERFORMANCE ANALYSIS:\")\n",
    "    print(\"-\" * 40)\n",
    "    class_metrics = []\n",
    "    for class_name in class_names:\n",
    "        if class_name in report:\n",
    "            metrics = report[class_name]\n",
    "            class_metrics.append({\n",
    "                'class': class_name,\n",
    "                'precision': metrics['precision'],\n",
    "                'recall': metrics['recall'],\n",
    "                'f1': metrics['f1-score'],\n",
    "                'support': metrics['support']\n",
    "            })\n",
    "    \n",
    "    # Sort by F1-score\n",
    "    class_metrics.sort(key=lambda x: x['f1'], reverse=True)\n",
    "    \n",
    "    print(f\"{'Class':<15} {'Precision':<10} {'Recall':<10} {'F1-Score':<10} {'Support':<10}\")\n",
    "    print(\"-\" * 65)\n",
    "    for metrics in class_metrics:\n",
    "        print(f\"{metrics['class']:<15} {metrics['precision']:<10.3f} {metrics['recall']:<10.3f} \"\n",
    "              f\"{metrics['f1']:<10.3f} {metrics['support']:<10}\")\n",
    "    \n",
    "    # Best and worst performing classes\n",
    "    best_class = class_metrics[0]\n",
    "    worst_class = class_metrics[-1]\n",
    "    \n",
    "    print(f\"\\nBEST PERFORMING CLASS: {best_class['class']} (F1: {best_class['f1']:.3f})\")\n",
    "    print(f\"WORST PERFORMING CLASS: {worst_class['class']} (F1: {worst_class['f1']:.3f})\")\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    return report\n",
    "\n",
    "# Final evaluation\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL EVALUATION - LENET-5 ON TIFINAGH CHARACTERS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get final predictions on validation set\n",
    "model.eval()\n",
    "final_predictions = []\n",
    "final_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        final_predictions.extend(predicted.cpu().numpy())\n",
    "        final_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Get class names\n",
    "class_names = [dataset.idx_to_label[i] for i in range(num_classes)]\n",
    "\n",
    "# Create all visualizations\n",
    "print(\"Generating visualizations...\")\n",
    "\n",
    "# 1. Training curves\n",
    "plot_training_curves(train_losses, val_losses, train_accuracies, val_accuracies)\n",
    "\n",
    "# 2. Confusion matrix\n",
    "cm = plot_confusion_matrix(final_labels, final_predictions, class_names)\n",
    "\n",
    "# 3. Evaluation report\n",
    "report = generate_evaluation_report(final_labels, final_predictions, class_names)\n",
    "\n",
    "# Training summary\n",
    "print(f\"\\nTRAINING SUMMARY:\")\n",
    "print(f\"Best validation accuracy: {max(val_accuracies):.2f}%\")\n",
    "print(f\"Final validation accuracy: {val_accuracies[-1]:.2f}%\")\n",
    "print(f\"Lowest validation loss: {min(val_losses):.4f}\")\n",
    "print(f\"Total parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbc4c56-0f50-4f29-8252-9c2bdf0c758d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
